[W824 18:43:01.286339622 OperatorEntry.cpp:154] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::_validate_compressed_sparse_indices(bool is_crow, Tensor compressed_idx, Tensor plain_idx, int cdim, int dim, int nnz) -> ()
    registered at /pytorch/build/aten/src/ATen/RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:30477
       new kernel: registered at /build/intel-pytorch-extension/build/Release/csrc/gpu/csrc/aten/generated/ATen/RegisterXPU.cpp:468 (function operator())
/opt/venv/lib/python3.12/site-packages/intel_extension_for_pytorch/nn/utils/_weight_prepack.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
[W824 18:43:03.416613656 OperatorEntry.cpp:154] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::_validate_compressed_sparse_indices(bool is_crow, Tensor compressed_idx, Tensor plain_idx, int cdim, int dim, int nnz) -> ()
    registered at /pytorch/build/aten/src/ATen/RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:30477
       new kernel: registered at /build/intel-pytorch-extension/build/Release/csrc/gpu/csrc/aten/generated/ATen/RegisterXPU.cpp:468 (function operator())
/opt/venv/lib/python3.12/site-packages/intel_extension_for_pytorch/nn/utils/_weight_prepack.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Loading global_model_openvino_model for OpenVINO inference...
Using OpenVINO LATENCY mode for batch=1 inference on GPU.0...

image 1/100 /app/Datasets/Purple_grapes/test/images/1002.png: 640x640 1 0, 32.5ms
image 2/100 /app/Datasets/Purple_grapes/test/images/1029.png: 640x640 2 0s, 27.6ms
image 3/100 /app/Datasets/Purple_grapes/test/images/1038.png: 640x640 5 0s, 27.7ms
image 4/100 /app/Datasets/Purple_grapes/test/images/1073.png: 640x640 4 0s, 27.7ms
image 5/100 /app/Datasets/Purple_grapes/test/images/1083.png: 640x640 3 0s, 27.8ms
image 6/100 /app/Datasets/Purple_grapes/test/images/1100.png: 640x640 6 0s, 27.8ms
image 7/100 /app/Datasets/Purple_grapes/test/images/1112.png: 640x640 5 0s, 27.7ms
image 8/100 /app/Datasets/Purple_grapes/test/images/1118.png: 640x640 4 0s, 27.6ms
image 9/100 /app/Datasets/Purple_grapes/test/images/1143.png: 640x640 2 0s, 28.6ms
image 10/100 /app/Datasets/Purple_grapes/test/images/1156.png: 640x640 2 0s, 28.5ms
image 11/100 /app/Datasets/Purple_grapes/test/images/1175.png: 640x640 6 0s, 27.9ms
image 12/100 /app/Datasets/Purple_grapes/test/images/1179.png: 640x640 8 0s, 27.8ms
image 13/100 /app/Datasets/Purple_grapes/test/images/1182.png: 640x640 1 0, 27.8ms
image 14/100 /app/Datasets/Purple_grapes/test/images/1184.png: 640x640 6 0s, 27.9ms
image 15/100 /app/Datasets/Purple_grapes/test/images/1185.png: 640x640 4 0s, 27.8ms
image 16/100 /app/Datasets/Purple_grapes/test/images/1188.png: 640x640 4 0s, 27.8ms
image 17/100 /app/Datasets/Purple_grapes/test/images/1194.png: 640x640 5 0s, 27.8ms
image 18/100 /app/Datasets/Purple_grapes/test/images/1197.png: 640x640 3 0s, 28.0ms
image 19/100 /app/Datasets/Purple_grapes/test/images/1207.png: 640x640 2 0s, 27.5ms
image 20/100 /app/Datasets/Purple_grapes/test/images/1209.png: 640x640 7 0s, 27.8ms
image 21/100 /app/Datasets/Purple_grapes/test/images/1214.png: 640x640 2 0s, 27.7ms
image 22/100 /app/Datasets/Purple_grapes/test/images/1229.png: 640x640 4 0s, 27.8ms
image 23/100 /app/Datasets/Purple_grapes/test/images/1231.png: 640x640 3 0s, 27.9ms
image 24/100 /app/Datasets/Purple_grapes/test/images/1232.png: 640x640 3 0s, 27.7ms
image 25/100 /app/Datasets/Purple_grapes/test/images/1275.png: 640x640 3 0s, 27.7ms
image 26/100 /app/Datasets/Purple_grapes/test/images/1286.png: 640x640 5 0s, 27.7ms
image 27/100 /app/Datasets/Purple_grapes/test/images/1304.png: 640x640 4 0s, 27.8ms
image 28/100 /app/Datasets/Purple_grapes/test/images/1310.png: 640x640 7 0s, 27.8ms
image 29/100 /app/Datasets/Purple_grapes/test/images/1314.png: 640x640 5 0s, 27.7ms
image 30/100 /app/Datasets/Purple_grapes/test/images/1315.png: 640x640 5 0s, 27.7ms
image 31/100 /app/Datasets/Purple_grapes/test/images/1318.png: 640x640 5 0s, 27.7ms
image 32/100 /app/Datasets/Purple_grapes/test/images/1325.png: 640x640 8 0s, 27.7ms
image 33/100 /app/Datasets/Purple_grapes/test/images/1335.png: 640x640 5 0s, 27.7ms
image 34/100 /app/Datasets/Purple_grapes/test/images/1336.png: 640x640 3 0s, 29.0ms
image 35/100 /app/Datasets/Purple_grapes/test/images/1346.png: 640x640 2 0s, 27.7ms
image 36/100 /app/Datasets/Purple_grapes/test/images/1359.png: 640x640 7 0s, 27.6ms
image 37/100 /app/Datasets/Purple_grapes/test/images/1378.png: 640x640 7 0s, 27.6ms
image 38/100 /app/Datasets/Purple_grapes/test/images/1396.png: 640x640 6 0s, 27.7ms
image 39/100 /app/Datasets/Purple_grapes/test/images/1410.png: 640x640 9 0s, 27.7ms
image 40/100 /app/Datasets/Purple_grapes/test/images/1416.png: 640x640 3 0s, 27.9ms
image 41/100 /app/Datasets/Purple_grapes/test/images/1436.png: 640x640 7 0s, 27.7ms
image 42/100 /app/Datasets/Purple_grapes/test/images/1439.png: 640x640 5 0s, 27.6ms
image 43/100 /app/Datasets/Purple_grapes/test/images/1455.png: 640x640 4 0s, 27.6ms
image 44/100 /app/Datasets/Purple_grapes/test/images/1457.png: 640x640 4 0s, 27.7ms
image 45/100 /app/Datasets/Purple_grapes/test/images/1473.png: 640x640 6 0s, 27.6ms
image 46/100 /app/Datasets/Purple_grapes/test/images/1481.png: 640x640 4 0s, 27.6ms
image 47/100 /app/Datasets/Purple_grapes/test/images/1500.png: 640x640 4 0s, 27.6ms
image 48/100 /app/Datasets/Purple_grapes/test/images/1502.png: 640x640 3 0s, 27.7ms
image 49/100 /app/Datasets/Purple_grapes/test/images/1507.png: 640x640 5 0s, 27.5ms
image 50/100 /app/Datasets/Purple_grapes/test/images/1508.png: 640x640 3 0s, 27.6ms
image 51/100 /app/Datasets/Purple_grapes/test/images/1512.png: 640x640 1 0, 27.8ms
image 52/100 /app/Datasets/Purple_grapes/test/images/1517.png: 640x640 4 0s, 27.7ms
image 53/100 /app/Datasets/Purple_grapes/test/images/1533.png: 640x640 2 0s, 27.5ms
image 54/100 /app/Datasets/Purple_grapes/test/images/1536.png: 640x640 2 0s, 27.6ms
image 55/100 /app/Datasets/Purple_grapes/test/images/1546.png: 640x640 4 0s, 27.7ms
image 56/100 /app/Datasets/Purple_grapes/test/images/1554.png: 640x640 2 0s, 27.7ms
image 57/100 /app/Datasets/Purple_grapes/test/images/1558.png: 640x640 4 0s, 27.7ms
image 58/100 /app/Datasets/Purple_grapes/test/images/1563.png: 640x640 5 0s, 27.6ms
image 59/100 /app/Datasets/Purple_grapes/test/images/1569.png: 640x640 7 0s, 27.6ms
image 60/100 /app/Datasets/Purple_grapes/test/images/1576.png: 640x640 7 0s, 27.8ms
image 61/100 /app/Datasets/Purple_grapes/test/images/1600.png: 640x640 4 0s, 27.8ms
image 62/100 /app/Datasets/Purple_grapes/test/images/1608.png: 640x640 6 0s, 27.7ms
image 63/100 /app/Datasets/Purple_grapes/test/images/1610.png: 640x640 5 0s, 27.4ms
image 64/100 /app/Datasets/Purple_grapes/test/images/1642.png: 640x640 6 0s, 27.7ms
image 65/100 /app/Datasets/Purple_grapes/test/images/1665.png: 640x640 7 0s, 27.5ms
image 66/100 /app/Datasets/Purple_grapes/test/images/1676.png: 640x640 3 0s, 27.9ms
image 67/100 /app/Datasets/Purple_grapes/test/images/1690.png: 640x640 7 0s, 27.9ms
image 68/100 /app/Datasets/Purple_grapes/test/images/1700.png: 640x640 6 0s, 28.0ms
image 69/100 /app/Datasets/Purple_grapes/test/images/1727.png: 640x640 3 0s, 28.0ms
image 70/100 /app/Datasets/Purple_grapes/test/images/1729.png: 640x640 6 0s, 27.8ms
image 71/100 /app/Datasets/Purple_grapes/test/images/1730.png: 640x640 1 0, 27.9ms
image 72/100 /app/Datasets/Purple_grapes/test/images/1745.png: 640x640 7 0s, 27.8ms
image 73/100 /app/Datasets/Purple_grapes/test/images/1756.png: 640x640 5 0s, 27.9ms
image 74/100 /app/Datasets/Purple_grapes/test/images/1764.png: 640x640 5 0s, 27.9ms
image 75/100 /app/Datasets/Purple_grapes/test/images/1770.png: 640x640 7 0s, 27.8ms
image 76/100 /app/Datasets/Purple_grapes/test/images/1780.png: 640x640 3 0s, 27.8ms
image 77/100 /app/Datasets/Purple_grapes/test/images/1785.png: 640x640 6 0s, 27.7ms
image 78/100 /app/Datasets/Purple_grapes/test/images/1795.png: 640x640 5 0s, 27.8ms
image 79/100 /app/Datasets/Purple_grapes/test/images/1804.png: 640x640 6 0s, 27.6ms
image 80/100 /app/Datasets/Purple_grapes/test/images/1825.png: 640x640 4 0s, 27.7ms
image 81/100 /app/Datasets/Purple_grapes/test/images/1832.png: 640x640 7 0s, 27.8ms
image 82/100 /app/Datasets/Purple_grapes/test/images/1833.png: 640x640 4 0s, 27.7ms
image 83/100 /app/Datasets/Purple_grapes/test/images/1857.png: 640x640 5 0s, 27.9ms
image 84/100 /app/Datasets/Purple_grapes/test/images/1869.png: 640x640 9 0s, 27.7ms
image 85/100 /app/Datasets/Purple_grapes/test/images/1878.png: 640x640 1 0, 27.8ms
image 86/100 /app/Datasets/Purple_grapes/test/images/1884.png: 640x640 5 0s, 27.8ms
image 87/100 /app/Datasets/Purple_grapes/test/images/1890.png: 640x640 8 0s, 27.8ms
image 88/100 /app/Datasets/Purple_grapes/test/images/1891.png: 640x640 6 0s, 27.8ms
image 89/100 /app/Datasets/Purple_grapes/test/images/1905.png: 640x640 3 0s, 27.8ms
image 90/100 /app/Datasets/Purple_grapes/test/images/1914.png: 640x640 6 0s, 28.7ms
image 91/100 /app/Datasets/Purple_grapes/test/images/1920.png: 640x640 8 0s, 27.7ms
image 92/100 /app/Datasets/Purple_grapes/test/images/1930.png: 640x640 7 0s, 27.7ms
image 93/100 /app/Datasets/Purple_grapes/test/images/1949.png: 640x640 4 0s, 27.7ms
image 94/100 /app/Datasets/Purple_grapes/test/images/955.png: 640x640 3 0s, 27.8ms
image 95/100 /app/Datasets/Purple_grapes/test/images/959.png: 640x640 2 0s, 27.8ms
image 96/100 /app/Datasets/Purple_grapes/test/images/961.png: 640x640 3 0s, 27.8ms
image 97/100 /app/Datasets/Purple_grapes/test/images/987.png: 640x640 1 0, 27.7ms
image 98/100 /app/Datasets/Purple_grapes/test/images/989.png: 640x640 6 0s, 27.8ms
image 99/100 /app/Datasets/Purple_grapes/test/images/991.png: 640x640 2 0s, 27.5ms
image 100/100 /app/Datasets/Purple_grapes/test/images/997.png: 640x640 2 0s, 27.6ms
Speed: 1.6ms preprocess, 27.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)
Results saved to [1mruns/detect/predict[0m
Inference complete. Results saved to inference_benchmark_results.csv
